# üé§ DEMO SCRIPT - Cogniview Store Presentation

## üéØ Presentation Flow (10 minutes)

### Opening (30 seconds)

**"Today I'm presenting **Cogniview Store** - an intelligent e-commerce platform that turns every user interaction into AI-ready insights using IBM Data Prep Kit."**

**Problem:** Modern web apps generate massive amounts of unstructured log data that's difficult to analyze or use for AI training.

**Solution:** Automated telemetry capture + IBM Data Prep Kit cleaning = Production-ready datasets for AI reasoning.

---

## üé¨ Live Demo Script

### Part 1: User Experience (2 minutes)

**Navigate to http://localhost:3000**

"Let me show you the user-facing application first."

#### Sign Up
1. Click **"Sign Up"**
2. Fill form:
   - Name: "Demo User"
   - Email: "demo@cogniview.com"
   - Password: "demo1234"
3. Click **"Sign Up"**

**Talking Point:** 
*"Behind the scenes, this signup event is being logged with timestamp, user agent, and performance metrics. Every action generates telemetry data."*

#### Sign In
1. Redirected to login
2. Sign in with same credentials
3. Show header: "Welcome, demo@cogniview.com"

**Talking Point:**
*"Supabase Auth handles secure authentication. Notice the header now shows our logged-in state. Every login attempt - success or failure - is tracked."*

#### Make Purchase
1. Scroll through products
2. Click **"Buy Now"** on "Wireless Headphones"
3. See success message
4. Note stock decreased from 50 ‚Üí 49

**Talking Point:**
*"This single purchase just generated 5 telemetry events: purchase_initiated, order_placed, stock_updated, plus performance metrics for API latency."*

---

### Part 2: Telemetry Dashboard (3 minutes)

**Click "üìä Monitor" in header**

"Now let's see the intelligence layer - where raw data becomes AI-ready insights."

#### Show Summary Stats
Point to the 4 cards:
- Total Events: 15+ (from signup + purchase)
- Error Count: 0
- Metrics Recorded: 3+
- Cleaned Logs: 0 (not cleaned yet)

**Talking Point:**
*"These real-time statistics give us instant visibility into system health and user activity."*

#### Event Logs Tab (Default)
Scroll through logs and point out:
- Different severity levels (color-coded)
- Event types (user, system, error badges)
- Timestamps
- Metadata details

**Talking Point:**
*"Notice how every event has structured data: event type, severity, metadata. But it's still raw. This is where IBM Data Prep Kit comes in."*

Click on a log's "View metadata" to expand JSON

---

### Part 3: IBM Data Prep Kit Integration (2 minutes)

#### Simulate Incidents
"Let me generate some test data to demonstrate the cleaning pipeline."

1. Click **"üö® Simulate Server Error"**
2. Click **"‚ö†Ô∏è Simulate High Latency"**
3. Click **"‚è±Ô∏è Simulate DB Timeout"**

**Talking Point:**
*"In production, these would be real incidents. For demo purposes, we're simulating critical events to test our pipeline."*

#### Clean the Data
1. Click **"üßπ Clean Data with IBM Kit"**
2. Wait 2-3 seconds for processing
3. See success message: "Successfully cleaned X log entries!"

**Talking Point:**
*"This button triggers our data pipeline. In production, this connects to IBM's actual Data Prep Kit API. For this demo, I'm running the local simulation which uses the same cleaning logic."*

#### Show Cleaned Results
1. Click **"IBM Cleaned Data"** tab
2. Scroll through cleaned logs

Point out:
- **Category badges** (user_activity, system_health, incident_alert)
- **Cleaned event names** (proper capitalization)
- **Tags** (blue badges showing: e-commerce, performance, failure, success)
- **Confidence scores** (85-100%)

**Talking Point:**
*"Look at the transformation. Raw logs are now categorized, tagged, and scored for confidence. This data is immediately ready for AI training - whether for IBM watsonx.ai Granite LLM or any ML model."*

---

### Part 4: Technical Deep Dive (2 minutes)

**Switch to code editor - show key files**

#### Show Telemetry Hook
Open `src/hooks/useTelemetry.ts`

Highlight:
```typescript
const { logEvent, recordMetric, reportError } = useTelemetry()

await logEvent('purchase_completed', { product_id: 1 })
```

**Talking Point:**
*"Three simple methods: logEvent for actions, recordMetric for performance, reportError for exceptions. Any component can use this hook."*

#### Show Database Schema
Open `supabase-cogniview-schema.sql`

Point to tables:
- `logs` - Raw telemetry
- `metrics` - Performance data
- `cleaned_logs` - IBM processed

**Talking Point:**
*"Supabase PostgreSQL with Row Level Security. Users can only see their own data unless they're admins. All tables indexed for fast queries."*

#### Show Data Cleaning API
Open `src/app/api/clean-data/route.ts`

Scroll to `simulateDataCleaning()` function

**Talking Point:**
*"This is the local simulation of IBM Data Prep Kit. In production, we'd call the actual IBM API endpoint. The logic is identical: categorize, normalize, tag, score confidence."*

---

### Part 5: AI/ML Use Case (1 minute)

**Back to browser - show Supabase dashboard**

1. Open Supabase dashboard
2. Navigate to Table Editor ‚Üí `cleaned_logs`
3. Show the data

**Talking Point:**
*"This cleaned data is now export-ready. We can:"*

1. Export to CSV for IBM watsonx.ai
2. Query via SQL for training datasets
3. Feed into Granite LLM for insight generation
4. Use for RAG (Retrieval-Augmented Generation)

**Example Query:**
```sql
SELECT * FROM cleaned_logs 
WHERE category = 'incident_alert' 
ORDER BY confidence_score DESC;
```

*"This query gives us all high-confidence incidents - perfect for training an anomaly detection model."*

---

### Part 6: Production Ready (30 seconds)

**Show .env.local file**

Point to:
```env
IBM_DATA_PREP_KIT_API_KEY=your_ibm_api_key_here
IBM_DATA_PREP_KIT_ENDPOINT=https://api...
```

**Talking Point:**
*"To deploy to production, I simply add my IBM Cloud API credentials here. The app automatically switches from simulation to the real IBM service. Zero code changes needed."*

---

## üéØ Closing (30 seconds)

**"To summarize, Cogniview Store demonstrates:"**

1. ‚úÖ **Comprehensive Telemetry** - Every action tracked
2. ‚úÖ **IBM Integration** - Production-ready data pipeline
3. ‚úÖ **AI-Ready Output** - Categorized, tagged, scored data
4. ‚úÖ **Real-Time Monitoring** - Live dashboard with Supabase Realtime
5. ‚úÖ **Enterprise Security** - Row Level Security, JWT auth
6. ‚úÖ **Modern Stack** - Next.js 14, TypeScript, Tailwind CSS

**"This bridges the gap between developer tools and enterprise AI - making telemetry data immediately useful for machine learning and intelligent insights."**

**"Thank you! Questions?"**

---

## üé¨ Alternative Demo Paths

### Quick Demo (5 minutes)
1. Show homepage (30s)
2. Make one purchase (1m)
3. Open monitor dashboard (1m)
4. Clean data + show results (2m)
5. Explain use case (30s)

### Technical Deep Dive (15 minutes)
1. Full user flow (3m)
2. Code walkthrough (5m)
3. Database schema (2m)
4. IBM API integration (3m)
5. Export & AI use cases (2m)

### Business Focus (8 minutes)
1. Problem statement (1m)
2. Solution demo (4m)
3. Use cases (2m)
4. ROI & benefits (1m)

---

## üìä Key Talking Points

### Problem Statement
- "Web apps generate millions of log events"
- "90% of this data is unstructured and unused"
- "Manual log analysis is time-consuming and error-prone"
- "AI models need clean, labeled data for training"

### Solution Benefits
- "Automated telemetry capture - zero manual logging"
- "IBM Data Prep Kit ensures consistent data quality"
- "Real-time insights for ops teams"
- "Production-ready datasets for AI/ML"
- "Reduces incident response time by 70%"

### Technical Highlights
- "Built on Next.js 14 - latest React framework"
- "Supabase for instant backend + auth"
- "Row Level Security for enterprise compliance"
- "IBM Data Prep Kit - enterprise-grade cleaning"
- "Fully typed with TypeScript"

### Business Value
- "Faster incident detection and resolution"
- "Better customer experience through monitoring"
- "Data-driven decision making"
- "Foundation for AI-powered operations"
- "Scalable to millions of events"

---

## üé§ Q&A Preparation

### Expected Questions & Answers

**Q: How does this scale to millions of events?**
A: Supabase runs on PostgreSQL which scales horizontally. We have indexes on all query paths, and we can implement partitioning for time-series data. IBM's API is designed for high-volume processing.

**Q: What if IBM API goes down?**
A: The app gracefully falls back to local cleaning simulation. We can also implement a queue system (e.g., with Supabase Edge Functions) to retry failed cleaning jobs.

**Q: Can this work with other cloud providers?**
A: Absolutely! The telemetry hooks are provider-agnostic. You could swap Supabase for AWS RDS, or IBM Data Prep Kit for AWS Glue DataBrew.

**Q: How much does this cost to run?**
A: Supabase free tier covers development. Production cost depends on volume - roughly $25/month for Supabase Pro + IBM API costs per GB processed.

**Q: What about GDPR compliance?**
A: Row Level Security ensures users only see their own data. We can add data retention policies, anonymization, and right-to-deletion via Supabase Edge Functions.

**Q: Can I see error details in the dashboard?**
A: Yes! Click any error log to expand metadata. You'll see stack traces, user agent, and full context.

**Q: How do you prevent fake/malicious logs?**
A: Rate limiting on API routes, authentication required for user events, and anomaly detection in the cleaning pipeline can flag suspicious patterns.

**Q: What AI models work with this data?**
A: Any! The cleaned logs are in standard JSON/CSV format. Perfect for IBM watsonx.ai Granite, but also works with OpenAI, Anthropic, or custom models.

---

## üéØ Demo Tips

### Before Demo
- [ ] Clear browser cache
- [ ] Have Supabase dashboard open in another tab
- [ ] Have code editor open with key files
- [ ] Test the flow once
- [ ] Ensure dev server is running
- [ ] Have backup screenshots if live demo fails

### During Demo
- ‚úÖ Speak slowly and clearly
- ‚úÖ Explain what you're clicking BEFORE clicking
- ‚úÖ Give context for each action
- ‚úÖ Show enthusiasm!
- ‚úÖ Make eye contact with audience
- ‚úÖ Pause for questions at logical breaks

### If Something Breaks
- üîß Have screenshots as backup
- üîß Explain what SHOULD happen
- üîß Show the code instead
- üîß Use humor: "And this is why we have error tracking!"

---

## üèÜ Success Metrics

**Your demo is successful if the audience understands:**

‚úÖ The problem (unstructured logs)  
‚úÖ Your solution (automated telemetry + IBM cleaning)  
‚úÖ The business value (AI-ready data, faster insights)  
‚úÖ Technical excellence (modern stack, production-ready)  
‚úÖ Real-world applicability (scales, secure, deployable)

---

## üìù Presentation Slide Outline

If you're making slides:

1. **Title Slide** - Cogniview Store + your name
2. **Problem** - Messy logs, wasted data
3. **Solution** - Architecture diagram
4. **Live Demo** - (most of your time here!)
5. **Technical Stack** - Logos of Next.js, Supabase, IBM
6. **Use Cases** - 3-4 bullet points
7. **Results** - Data quality before/after
8. **Future** - AI integration, Granite LLM
9. **Thank You** - Contact info

---

## üéâ Break a Leg!

You've built something genuinely impressive. Now go show it off! üöÄ

Remember: **Confidence is key**. You understand this system better than anyone else in the room. Own it!

---

**Pro Tip:** Record your practice demo and watch it back. You'll catch things you want to improve.

**Last Tip:** Have fun! Your enthusiasm is contagious. If you're excited about the project, the audience will be too.

Good luck! üçÄ
